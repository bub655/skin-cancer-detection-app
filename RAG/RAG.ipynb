{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (3.10.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vinay/.local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (3.10.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (0.2.28)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vinay/.local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/vinay/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m619.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m197.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.11 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/vinay/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or `pip install bitsandbytes`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/vinay/Code/skin_cancer/RAG.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m#################################################################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# Load pre-trained config\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m#################################################################\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     model_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     quantization_config\u001b[39m=\u001b[39;49mbnb_config,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_number_of_trainable_model_parameters\u001b[39m(model):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vinay/Code/skin_cancer/RAG.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     trainable_model_params \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/Code/ML/OpenStreets/.conda/lib/python3.11/site-packages/transformers/modeling_utils.py:2899\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2898\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_accelerate_available() \u001b[39mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m-> 2899\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m   2900\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2901\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2902\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `pip install bitsandbytes`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2903\u001b[0m     )\n\u001b[1;32m   2905\u001b[0m \u001b[39mif\u001b[39;00m torch_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2906\u001b[0m     \u001b[39m# We force the `dtype` to be float16, this is a requirement from `bitsandbytes`\u001b[39;00m\n\u001b[1;32m   2907\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   2908\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOverriding torch_dtype=\u001b[39m\u001b[39m{\u001b[39;00mtorch_dtype\u001b[39m}\u001b[39;00m\u001b[39m with `torch_dtype=torch.float16` due to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrequirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m torch_dtype=torch.float16 to remove this warning.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2912\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or `pip install bitsandbytes`."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "  AutoTokenizer, \n",
    "  AutoModelForCausalLM, \n",
    "  BitsAndBytesConfig,\n",
    "  pipeline\n",
    ")\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "import transformers\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import nest_asyncio\n",
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token='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')\n",
    "\n",
    "model_name='KISTI-KONI/KONI-Llama3-8B-Instruct-20240729'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "!playwright install \n",
    "!playwright install-deps \n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Articles to index\n",
    "articles = [\"https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/\",\n",
    "            \"https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/\"]\n",
    "\n",
    "# Scrapes the blogs above\n",
    "loader = AsyncChromiumLoader(articles)\n",
    "docs = loader.load()\n",
    "\n",
    "# Converts HTML to plain text \n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Create prompt template\n",
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "\n",
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"Should I start Gibbs next week for fantasy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
